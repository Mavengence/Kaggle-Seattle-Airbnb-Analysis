{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4861 Group Project - Seattle Airbnb Dataset\n",
    "\n",
    "### I analyse the Kaggle dataset from Airbnb Seattle to deduce some customer behaviour and apply our information gain to do better marketing strategies and maximize the market value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Loehr/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Loehr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import glob\n",
    "import os, inspect\n",
    "from IPython.display import Image\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import operator\n",
    "from zipfile import ZipFile\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, CuDNNLSTM, Activation, Embedding\n",
    "import keras\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    nltk.download('stopwords')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into Panda Dateframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendar: (1393570, 4)\n",
      "Listings: (3818, 92)\n"
     ]
    }
   ],
   "source": [
    "path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) + \"/seattle\"\n",
    "\n",
    "zf = ZipFile(str(path) + '.zip', 'r')\n",
    "zf.extractall(path)\n",
    "\n",
    "filenames = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    all_data.append(df)\n",
    "\n",
    "#reviews = data[0]\n",
    "listings = all_data[1]\n",
    "calendar = all_data[2]\n",
    "\n",
    "calendar2 = calendar\n",
    "listings2 = listings\n",
    "\n",
    "print(\"Calendar: \" +str(calendar.shape))\n",
    "print(\"Listings: \" +str(listings.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(listings, calendar, left_on='id', right_on='listing_id', how='left').drop('listing_id', axis=1)\n",
    "dataset = dataset[::6]\n",
    "dataset = dataset.dropna(subset=['price_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are     5 unique '     host_response_time'\n",
      "There are    46 unique '     host_response_rate'\n",
      "There are     3 unique '   host_acceptance_rate'\n",
      "There are   338 unique '               bedrooms'\n",
      "There are   815 unique '              bathrooms'\n",
      "There are    71 unique '                   beds'\n",
      "There are   195 unique '      number_of_reviews'\n",
      "There are  1361 unique '             host_since'\n",
      "There are     3 unique '              room_type'\n",
      "There are    45 unique '           extra_people'\n",
      "There are     3 unique ' host_identity_verified'\n",
      "There are    15 unique '        guests_included'\n",
      "There are   554 unique '                price_y'\n",
      "\n",
      "------------------------\n",
      "For 155769 total entries\n"
     ]
    }
   ],
   "source": [
    "# tags with the price -> full dataset\n",
    "tags = ['host_response_time', 'host_response_rate', 'host_acceptance_rate', 'bedrooms', 'bathrooms', \n",
    "        'beds', 'number_of_reviews','host_since', 'room_type', 'extra_people', 'host_identity_verified',\n",
    "        'guests_included', 'price_y']\n",
    "\n",
    "# Tags without the price_y to split into \"X\" and the price_y to \"Y\" datasets.\n",
    "tags_x = ['host_response_time', 'host_response_rate', 'host_acceptance_rate', 'bedrooms', \n",
    "          'bathrooms', 'beds', 'number_of_reviews','host_since', 'room_type', 'extra_people', \n",
    "          'host_identity_verified', 'guests_included']\n",
    "\n",
    "for col in tags:    \n",
    "    idsUnique = len(set(dataset[col])) \n",
    "    idsTotal = dataset.shape[0] \n",
    "    idsDupli = idsTotal - idsUnique\n",
    "    print(\"There are %5d unique '%23s'\" % (idsUnique, col))\n",
    "print()\n",
    "print(\"------------------------\")\n",
    "print(\"For %d total entries\" % idsTotal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the rows with missing values up with default values to be able to calculate\n",
    "\n",
    "dataset.loc[:, \"host_response_time\"] = dataset.loc[:, \"host_response_time\"].fillna(0)\n",
    "dataset.loc[:, \"host_response_rate\"] = dataset.loc[:, \"host_response_rate\"].fillna(0)\n",
    "dataset.loc[:, \"host_acceptance_rate\"] = dataset.loc[:, \"host_acceptance_rate\"].fillna(0)\n",
    "dataset.loc[:, \"bathrooms\"] = dataset.loc[:, \"bathrooms\"].fillna(0)\n",
    "dataset.loc[:, \"bedrooms\"] = dataset.loc[:, \"bedrooms\"].fillna(0)\n",
    "dataset.loc[:, \"beds\"] = dataset.loc[:, \"beds\"].fillna(0)\n",
    "dataset.loc[:, \"number_of_reviews\"] = dataset.loc[:, \"number_of_reviews\"].fillna(0)\n",
    "dataset.loc[:, \"host_since\"] = dataset.loc[:, \"host_since\"].fillna(2018)\n",
    "dataset.loc[:, \"room_type\"] = dataset.loc[:, \"room_type\"].fillna('Private room')\n",
    "dataset.loc[:, \"extra_people\"] = dataset.loc[:, \"extra_people\"].fillna(0)\n",
    "dataset.loc[:, \"host_identity_verified\"] = dataset.loc[:, \"host_identity_verified\"].fillna('f')\n",
    "dataset.loc[:, \"guests_included\"] = dataset.loc[:, \"guests_included\"].fillna(0)\n",
    "\n",
    "dataset['host_response_rate'] = [rate.replace('%', '') for rate in dataset['host_response_rate'].astype(str)]\n",
    "dataset['bedrooms'] = dataset['bedrooms'].astype('int32')\n",
    "dataset['bathrooms'] = dataset['bathrooms'].astype('int32')\n",
    "dataset['beds'] = dataset['beds'].astype('int32')\n",
    "dataset['host_since'] = [host[:4] for host in dataset['host_since'].astype(str)]\n",
    "dataset['extra_people'] = [extra[:-3].replace('$', '') for extra in dataset['extra_people'].astype(str)]\n",
    "dataset['price_y'] = [price[:-3].replace('$', '').replace(',', '') for price in dataset['price_y'].astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical with numerical values to be able to fit the models\n",
    "\n",
    "dataset = dataset.replace({\"host_response_time\" : {np.isnan : 0, 'a few days or more' : 1, 'within a day' : 2, \n",
    "                                                   'within a few hours' : 3, 'within an hour': 4},\n",
    "                          \"host_acceptance_rate\" : {'0%': 0, '100%': 1},\n",
    "                           \"room_type\" : {'Entire home/apt': 3, 'Private room': 2, 'Shared room' : 1},\n",
    "                           \"host_identity_verified\" : {\"f\" : 0, \"t\" : 1}\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train data shape: (104365, 12)\n",
      "y Train data shape: (104365,)\n",
      "X Test data shape: (51404, 12)\n",
      "y Train data shape: (51404,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['price_y']\n",
    "dataset = dataset.drop('price_y', 1)\n",
    "\n",
    "# Split the data into Train 66% and Test 33%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[tags_x].astype(int), y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"X Train data shape: \" +str(X_train.shape))\n",
    "print(\"y Train data shape: \" + str(y_train.shape))\n",
    "print(\"X Test data shape: \" + str(X_test.shape))\n",
    "print(\"y Train data shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find correlation between amount of bedrooms and the price of the flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort by the amount of bedrooms to plot it correctly\n",
    "sorted_x = pd.DataFrame([X_train['bedrooms'], y_train]).T.astype(int)\n",
    "sorted_x = sorted_x.sort_values(by=['price_y'])\n",
    "\n",
    "plt.scatter(sorted_x.bedrooms, sorted_x.price_y)\n",
    "plt.title(\"Bedrooms price correlation\")\n",
    "plt.xlabel(\"Number bedrooms\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.yticks(np.arange(50, 2000, 200))\n",
    "plt.xticks(np.arange(1, len(set(sorted_x.bedrooms))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model to predict the y_price of the data with MAE as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute Error :     44.28\n",
      "Mean squared Error  :   5022.98\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean absolute Error : {:9.2f}\".format(round(mae, 2)))\n",
    "print(\"Mean squared Error  : {:9.2f}\".format(round(mse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104365, 12, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fit the data into the Neural Network, we need to create a new dimension, because the LSTM model\n",
    "# expect format like (12, 1), since our data is 104365 and 12 features, we need to reshape it to (104365, 12, 1)\n",
    "# and cut away the first dimension when we give it as parameter to the neural net -> (12, 1)\n",
    "\n",
    "Xtrain = np.array(X_train)\n",
    "trainXs = Xtrain[:,:, newaxis]\n",
    "trainXs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 12 input nodes, 32 nodes in the single hidden Layer and 1 Output Node\n",
    "# In total that makes 12*32 + 12 + 1 + 32*1 = 429 Nodes to train for 104365 data in the dataset\n",
    "\n",
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(32, input_shape=trainXs.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.005), loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104365/104365 [==============================] - 11s 103us/step - loss: 124.2075\n",
      "Epoch 2/5\n",
      "104365/104365 [==============================] - 9s 83us/step - loss: 104.9781\n",
      "Epoch 3/5\n",
      "102400/104365 [============================>.] - ETA: 0s - loss: 89.5892"
     ]
    }
   ],
   "source": [
    "simple_lstm_model.fit(trainXs, y_train, epochs=5, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I try to find out the vibe of the neighbourhood by doing sentiment analysis of the reviews of the customers and extract the peoples thoughts about the accommodation and city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "# Stem the words to their origin:  played -> play\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# combine review with city name together in data array\n",
    "for nh, overview in zip(listings['neighbourhood'].dropna().astype(str), listings['neighborhood_overview'].astype(str)):\n",
    "    if(nh in data):\n",
    "        data[nh] += overview\n",
    "    else:\n",
    "        data[nh] = overview\n",
    "\n",
    "nb_vibe = {}\n",
    "nb_freq = {} \n",
    " \n",
    "# Natural Language Processing Preprocessing for all the reviews\n",
    "for nh in data:\n",
    "    t = RegexpTokenizer(r'\\w+')     # Get rid of .,?!\"\" and additional spaces\n",
    "    tokens = t.tokenize(data[nh])   # Tokenize a sentence and splits it by a space\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))   # Remove Stopwords aka \"and\" or \"with\"\n",
    "    stop_words2 = [*nh.lower().split(' '), 'seattle', 'neighborhood']   # lower the caps of the words\n",
    "    \n",
    "    # Apply all of that\n",
    "    tokens = [w.lower() for w in tokens if not w in stop_words]\n",
    "    tokens = [w for w in tokens if not w in stop_words2]\n",
    "    tokens = [stemmer.stem(WordNetLemmatizer().lemmatize(token, pos='v')) for token in tokens]\n",
    "    \n",
    "    # Calculate the frequency count of the words\n",
    "    frequency_dist = nltk.FreqDist(tokens)\n",
    "    nb_freq[nh] = frequency_dist\n",
    "    \n",
    "    # I store the 50 most used words in the nb_vibe array\n",
    "    nb_vibe[nh] = sorted(frequency_dist, key=frequency_dist.__getitem__, reverse=True)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 6 citys with the most reviews to apply the 50 most frequent words on\n",
    "max_words = {}\n",
    "for nh in nb_vibe:\n",
    "    max_words[nh] = len(data[nh])\n",
    "    \n",
    "top_reviewed_citys = sorted(max_words, key=max_words.get)[::-1][:6]\n",
    "print(top_reviewed_citys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Wordcloud to visualize the 50 most used words in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(nrows=3, ncols=2, figsize=(17,15))\n",
    "axs = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "\n",
    "for ax, city in zip(axs, top_reviewed_citys):\n",
    "    wordcloud = WordCloud(max_font_size=100, \n",
    "                          max_words=20, background_color=\"white\").generate_from_frequencies(nb_freq[city])\n",
    "    ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(city, fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = listings[['review_scores_value', 'neighbourhood']].dropna()\n",
    "X = np.array(nb['neighbourhood'])\n",
    "y = np.array(nb['review_scores_value'].astype(int))\n",
    "\n",
    "print(\"X: Neighbourhood: \" + str(X.shape))\n",
    "print(\"Y: Score for the accommodation: \" +str(y.shape))\n",
    "print(\"Unique Neighbourhoods: \" + str(len(set(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the scores to the unique citys\n",
    "rating = dict()\n",
    "\n",
    "for r, nb in zip(y, X):\n",
    "    if(nb not in rating):\n",
    "        rating[nb] = [r, 1]\n",
    "    else:\n",
    "        rating[nb][0] += r\n",
    "        rating[nb][1] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To understand the value of a review score i visualize the all the scores the people gave to the airbnb accommodations. \n",
    "\n",
    "It seems that the people have a high tendencie to rate the accommodation pretty high, which results in rather unprecise analysis. The score of the review is nothing to highly rely on.\n",
    "\n",
    "This is why i use the amount of reviews used for every city and not decide by the mean score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = listings[['neighborhood_overview', 'review_scores_value', 'neighbourhood']].dropna()\n",
    "text = np.array(nb['neighborhood_overview'])\n",
    "label = nb['review_scores_value'].astype(int)\n",
    "\n",
    "# Sort, Sum and ocunt the ratings of all the citys\n",
    "x = sorted(rating.items(), key=lambda x: x[1])[::-1][:20]\n",
    "names = [x[0] for x in x]\n",
    "x_sum = [x[1][0] for x in x]\n",
    "y_count = [x[1][1] for x in x]\n",
    "x_mean = []\n",
    "\n",
    "for x, y in zip(x_sum, y_count):\n",
    "    x_mean.append(x/y)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n",
    "    \n",
    "ax1.hist(label)\n",
    "ax1.set_title(\"Occurrences of review scores\")\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    ax2.annotate(name, (x_mean[i], y_count[i]))\n",
    "\n",
    "ax2.scatter(x_mean, y_count)\n",
    "ax2.set_title(\"Compare the neighbourhoods\")\n",
    "ax2.set_ylabel(\"Number of Reviews\")\n",
    "ax2.set_xlabel(\"Mean Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busiest times of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = calendar.dropna()\n",
    "dates = calendar['date']\n",
    "price = calendar['price']\n",
    "\n",
    "year_date = {date: 0 for date in set(dates)}\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', \n",
    "         'October', 'November', 'December', 'January']\n",
    "\n",
    "for date in dates:\n",
    "    year_date[date] += 1\n",
    "\n",
    "# empty array to be filled with the monthly visitors per month\n",
    "monthly_visitors = np.zeros(12)\n",
    "    \n",
    "year_num = []\n",
    "\n",
    "# Iterate over all entries and append the single counts of customers\n",
    "for i, date in enumerate(year_date.items()):\n",
    "    year_num.append(date[1])\n",
    "    \n",
    "for date in year_date:\n",
    "    monthly_visitors[int(date.split('-')[1]) - 1] += year_date[date]\n",
    "\n",
    "monthly_visitors = [int(visitors) for visitors in monthly_visitors]\n",
    "\n",
    "print(\"Monthly visitors for example for January: \" +str(monthly_visitors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I estimate the amount of visitors for the year 2017 with a Polynomial Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(monthly_visitors)\n",
    "X = np.array(np.arange(1, 13))\n",
    "\n",
    "# Polynomial Regression expects a third dimension like the Neural Network (x, y, 1)\n",
    "X = X[:, np.newaxis]\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "# Fit the Polynomial Regression\n",
    "polynomial_features= PolynomialFeatures(degree=5)\n",
    "x_poly = polynomial_features.fit_transform(X)\n",
    "\n",
    "# Fit the Linear Regression\n",
    "linreg = linear_model.LinearRegression()\n",
    "linreg.fit(x_poly, y)\n",
    "\n",
    "# Predict all months in 2017\n",
    "y_poly_pred = linreg.predict(x_poly)\n",
    "\n",
    "#print(\"Y = \" + str(lr.coef_[0]) + \"X + \"+ str(round(lr.intercept_[0], 2)))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.scatter(X, y)\n",
    "plt.plot(np.arange(1, len(y_poly_pred) + 1), y_poly_pred)\n",
    "plt.plot(X, y_poly_pred, color=\"red\")\n",
    "plt.title(\"Prediction for 2017\", fontsize=20)\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Exact Visiter Count\")\n",
    "plt.yticks(np.arange(50000, 110000, 10000))\n",
    "plt.xticks(np.arange(1, 13), months)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I estimate the amount of daily visitors for the year 2016 with a Polynomial Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(year_num)\n",
    "X = np.array(np.arange(1, len(year_num) + 1))\n",
    "\n",
    "# Polynomial Regression expects a third dimension like the Neural Network (x, y, 1)\n",
    "X = X[:, np.newaxis]\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "# Fit the Polynomial Regression\n",
    "polynomial_features= PolynomialFeatures(degree=5)\n",
    "x_poly = polynomial_features.fit_transform(X)\n",
    "\n",
    "# Fit the Linear Regression\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_poly, y)\n",
    "y_pred = lr.predict(x_poly)\n",
    "\n",
    "print(\"Y = \" + str(lr.coef_[0]) + \"X + \"+ str(round(lr.intercept_[0], 2)))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(np.arange(1, len(year_num) + 1), year_num)\n",
    "plt.plot(X, y_pred, color=\"red\")\n",
    "plt.title(\"Busiest times of the year 2016\", fontsize=20)\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Exact Visiter Count\")\n",
    "plt.yticks(np.arange(1500, 3250, 150))\n",
    "plt.xticks(np.arange(1, 395, 31), months)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual occupation of the 3861 Airbnb accommodations\n",
    "\n",
    "Since it was hard figure out when a flat is really occupied by a costumer or when a flat is just currently not available, because the owner doesn't want people to live in at the moment, i assume that a free flat counts as no visitor and a occupied flat counts as a costumer is living in the flat.\n",
    "\n",
    "For this ratio between empty and occupied we did all the below calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame\n",
    "new_listings = listings2[['id', 'beds', 'availability_30', 'availability_365']] \n",
    "\n",
    "# Merge the Calendar and Listings DataFrame with neccessaty columns\n",
    "availability = pd.merge(new_listings, calendar2, left_on='id', right_on='listing_id', \n",
    "                        how='left').drop('listing_id', axis=1)\n",
    "# Little preprocessing\n",
    "availability = availability.replace({\"available\" : {\"t\": 1, \"f\": 0}}).drop('price', 1)\n",
    "\n",
    "# Devide and group by the free = 1 and occupied = 0 flats.\n",
    "daily_available = availability.groupby([availability.date, availability.available]).count()\n",
    "daily_available = np.array(daily_available['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Count of free and occupied days\n",
    "daily_free = daily_available[::2]\n",
    "daily_occupied = daily_available[1::2]\n",
    "\n",
    "# Ratios of free and occupied days\n",
    "daily_free_rate = (daily_free / (daily_free + daily_occupied))\n",
    "daily_occupied_rate = (daily_occupied / (daily_free + daily_occupied))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the ratio of the year 2016\n",
    "\n",
    "Since I use the ratio, the y axis at 1 signals the 100%. We can observe, that in January there is more or less half of all flats available, whereas there are 3 main intervalls over the year.\n",
    "Most people visit Seattle in April, end of June and Christmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "plt.bar(np.arange(1,366), daily_occupied_rate + daily_free_rate, width = 0.9, color='red',alpha=1, label=\"Occupied\")\n",
    "plt.bar(np.arange(1,366), daily_free_rate, width = 0.5, color='blue',alpha=1, label=\"Free\")\n",
    "plt.xlim(min(np.arange(1,366)), max(np.arange(1,366)))\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.legend(['Occupied', 'Free'], prop={'size': 16})\n",
    "plt.xlabel('Months',fontsize=15)\n",
    "plt.ylabel('Total Capacity',fontsize=15)\n",
    "plt.xticks(np.arange(1, 395, 31), months)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('Costumer living in flat per day',fontsize=15)\n",
    "plt.title('Accommodations ratio of being occupied and available in percent in year 2016',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for the mean calculation. More complicated programmed then neccessary.\n",
    "occupy_rate = pd.DataFrame()\n",
    "occupy_rate = availability.groupby([availability.date]).count()\n",
    "occupy_rate['rate'] = daily_occupied_rate\n",
    "most_visited_days = occupy_rate.sort_values('rate')[::-1][:30]\n",
    "\n",
    "# Assign new DataFrame\n",
    "date_price = calendar\n",
    "date_price = date_price[['date', 'price']].dropna(0)\n",
    "\n",
    "date_price['price'] = [x.replace('$', '')[:-3] for x in date_price['price']]\n",
    "date_price = date_price.sort_values(['date', 'price'])\n",
    "\n",
    "x = np.array(date_price['date'])\n",
    "y = np.array(date_price['price'])\n",
    "\n",
    "x_set = np.array([x for x in set(x)])\n",
    "x_set.shape\n",
    "\n",
    "monthly_mean = {x: [] for x in np.arange(1,13)}\n",
    "\n",
    "# Split date '2016-01-04' into ['2016', '01', '04'] to select by month\n",
    "for date, price in zip(x, y):\n",
    "    month = int(date.split('-')[1])\n",
    "    price = price.replace(',', '')\n",
    "    price = int(price)\n",
    "    monthly_mean[month].append(price)\n",
    "\n",
    "mean_prices = {x: 0 for x in np.arange(1,13)}\n",
    "\n",
    "# Append all entries to a new array to calculate mean\n",
    "for month in monthly_mean.items():\n",
    "    value = 0\n",
    "    for number in month[1]:\n",
    "        value += int(number)\n",
    "    value /= len(month[1])\n",
    "    mean_prices[month[0]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean\n",
    "mean_price = []\n",
    "for price in mean_prices.items():\n",
    "    mean_price.append(price[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The price fluctuation over the year 2016\n",
    "\n",
    "I can observe, that eventhough in christmas there is a peak of costumers, the price is rather low.\n",
    "Whereas in the June and July sommer vacation time, in which also a lot of people arrive, we have the highest price. \n",
    "\n",
    "The flat owners apparently try to make the most money out of the flats in the summer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "plt.title(\"Mean Flat prices over the year 2016\")\n",
    "plt.plot(np.arange(1, 13), mean_price, 'r->')\n",
    "plt.ylabel(\"Mean Price in $\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.xticks(np.arange(1, 14), months)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
